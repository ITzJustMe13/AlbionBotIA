{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import roboflow\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.111  Python-3.13.3 torch-2.6.0+cpu CPU (AMD Ryzen 5 8400F 6-Core Processor)\n",
      "Setup complete  (12 CPUs, 15.6 GB RAM, 747.8/930.8 GB disk)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T13:32:39.493907Z",
     "start_time": "2025-04-19T13:32:39.489668Z"
    }
   },
   "source": [
    "# Em apple sillicon, verificar se o MPS está disponível\n",
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino de um modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T14:17:37.004989Z",
     "start_time": "2025-04-19T14:17:35.296442Z"
    }
   },
   "source": [
    "# descarregar o dataset do roboflow, depois de etiquetadas as imagens e criado o dataset\n",
    "# em Mac tive problemas de permissões e foi necessário dar permissões à pasta de conf. do roboflow:\n",
    "# - sudo mkdir /Users/davidecarneiro/.config/roboflow (criar pasta onde vai guardar a conf.)\n",
    "# - sudo chown -R davidecarneiro:staff ~/.config/roboflow (dar permissões ao meu user)\n",
    "#roboflow.login()\n",
    "\n",
    "# criar um ficheiro com a key da api do roboflow, ou simplesmente substituir abaixo\n",
    "with open('api_key.txt', \"r\") as file:\n",
    "    api_key = file.read().strip() \n",
    "\n",
    "rf = roboflow.Roboflow(api_key)\n",
    "\n",
    "# substituir nome do workspace e do projeto\n",
    "project = rf.workspace(\"albiononline-ia\").project(\"albion-bot-e1ypw\")\n",
    "# se versão do dataset > 1, substituir pela versão correspondente\n",
    "dataset = project.version(4).download(\"yolov8\")\n",
    "# WARN: necessário verificar os paths no ficheiro data.yaml, após este ser descarregado"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T16:02:50.810429Z",
     "start_time": "2025-04-19T14:31:05.395690Z"
    }
   },
   "source": [
    "# treinar o modelo\n",
    "# lista de modelos pre-treinados disponível em https://docs.ultralytics.com/models/yolov8/#performance-metrics\n",
    "model = YOLO(\"yolov8m.pt\")  # carregar o modelo pre-treinado que se descarregou\n",
    "\n",
    "# Treinar o modelo\n",
    "#results = model.train(data='./data.yaml', epochs=20, imgsz=640, device=0) # intel/windows\n",
    "results = model.train(data='./data.yaml', epochs=20, imgsz=640, device=\"cpu\") # apple sillicon"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.111  Python-3.13.3 torch-2.6.0+cpu CPU (AMD Ryzen 5 8400F 6-Core Processor)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8m.pt, data=./data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.10.1 ms, read: 128.250.4 MB/s, size: 68.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\train\\labels... 273 images, 0 backgrounds, 0 corrupt: 100%|██████████| 273/273 [00:00<00:00, 2516.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\train\\labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.10.1 ms, read: 127.320.6 MB/s, size: 63.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\valid\\labels... 27 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27/27 [00:00<00:00, 3072.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\u001B[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.634      2.025      1.339         23        640: 100%|██████████| 18/18 [04:33<00:00, 15.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227       0.64      0.748      0.775      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      1.335      1.018      1.176         17        640: 100%|██████████| 18/18 [04:24<00:00, 14.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.865      0.766      0.855      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      1.248     0.8098        1.2          8        640: 100%|██████████| 18/18 [04:21<00:00, 14.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.305      0.549      0.271      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.206     0.7785      1.161          1        640: 100%|██████████| 18/18 [04:38<00:00, 15.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.471      0.503      0.479      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G       1.23      0.736       1.15         15        640: 100%|██████████| 18/18 [04:21<00:00, 14.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.831      0.767       0.86      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.197     0.6887      1.134         19        640: 100%|██████████| 18/18 [04:17<00:00, 14.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.768      0.755      0.901      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.222     0.6635      1.118         34        640: 100%|██████████| 18/18 [04:16<00:00, 14.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227       0.94      0.908      0.966      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.226     0.6725      1.221          8        640: 100%|██████████| 18/18 [04:19<00:00, 14.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227       0.89      0.886      0.957      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.201      0.611      1.177          4        640: 100%|██████████| 18/18 [04:17<00:00, 14.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.921      0.912      0.965       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.127     0.5875      1.089         17        640: 100%|██████████| 18/18 [04:18<00:00, 14.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.963      0.925      0.973      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      1.087     0.5077      1.186         12        640: 100%|██████████| 18/18 [04:16<00:00, 14.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.953      0.918      0.969        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.037     0.5267      1.142          1        640: 100%|██████████| 18/18 [04:32<00:00, 15.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.921      0.921      0.957      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      1.066     0.4869      1.129          3        640: 100%|██████████| 18/18 [04:26<00:00, 14.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.929      0.861      0.944       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G       1.03     0.4656      1.126         11        640: 100%|██████████| 18/18 [04:29<00:00, 14.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.931      0.951      0.977      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G     0.9882     0.4423      1.115         10        640: 100%|██████████| 18/18 [04:25<00:00, 14.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.952      0.921      0.975      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G     0.9548      0.433      1.086          3        640: 100%|██████████| 18/18 [04:27<00:00, 14.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.968      0.923      0.971      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G     0.9189     0.4121      1.091          9        640: 100%|██████████| 18/18 [04:26<00:00, 14.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.981      0.939      0.975       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G     0.8981     0.3963      1.073         12        640: 100%|██████████| 18/18 [04:24<00:00, 14.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.973      0.926      0.981      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G     0.8898     0.3911      1.026          8        640: 100%|██████████| 18/18 [04:28<00:00, 14.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.975      0.941      0.979      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G     0.8227     0.3698      1.013          1        640: 100%|██████████| 18/18 [04:24<00:00, 14.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.971      0.943      0.979      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 1.525 hours.\n",
      "Optimizer stripped from C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating C:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.111  Python-3.13.3 torch-2.6.0+cpu CPU (AMD Ryzen 5 8400F 6-Core Processor)\n",
      "Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         27        227      0.973      0.926      0.981      0.645\n",
      "          broken stone         16         71      0.966      0.915      0.977      0.595\n",
      "                 stone         27        156      0.981      0.936      0.986      0.695\n",
      "Speed: 1.8ms preprocess, 289.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\Francisco\\Desktop\\AlbionBotIA\\runs\\detect\\train\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência"
   ]
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%%sql\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T19:29:05.797831Z",
     "start_time": "2025-04-19T19:29:05.783711Z"
    }
   },
   "source": [
    "# selecionar a melhor versão do modelo fine-tuned\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# selecionar a melhor versão do modelo fine-tuned\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m model = \u001B[43mYOLO\u001B[49m(\u001B[33m\"\u001B[39m\u001B[33mruns/detect/train/weights/best.pt\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'YOLO' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T19:28:22.782166Z",
     "start_time": "2025-04-19T19:28:22.578108Z"
    }
   },
   "source": [
    "# prever em novas imagens\n",
    "confidence_level = 0.1\n",
    "input_path = 'captured_images'\n",
    "output_path = 'detections'\n",
    "class_names = model.names\n",
    "\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    if file.lower().endswith((\".png\")):\n",
    "        image = cv2.imread(os.path.join(input_path, file))\n",
    "        results = model.predict(source=image, conf=confidence_level)  # gerar previsões acima de determinada confiança, e guardar imagens\n",
    "\n",
    "        \n",
    "        output_filename = f\"prediction_{file}\"\n",
    "        output_filepath = os.path.join(output_path, output_filename)\n",
    "\n",
    "        for result in results:\n",
    "            result.save(filename=output_filepath)\n",
    "            print(\"==== Resultados Previsão ====\")\n",
    "            print(\"Imagem: \"+os.path.join(input_path, file))\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()  # Bounding boxes (x_min, y_min, x_max, y_max)\n",
    "            scores = result.boxes.conf.cpu().numpy()  # Score de confiança\n",
    "            labels = result.boxes.cls.cpu().numpy()  # Índice da classe\n",
    "\n",
    "            for i in range(len(boxes)):\n",
    "                class_id = labels[i]\n",
    "                class_label = class_names[class_id] if class_id in class_names else \"Desconhecido\"\n",
    "\n",
    "                print(f\"--- Objeto {i+1} ---\")\n",
    "                print(f\"Class: {class_label} (ID: {class_id})\")\n",
    "                print(f\"Coordenadas Bounding Box: {boxes[i]}\")\n",
    "                print(f\"Confiança: {scores[i]:.4f}\")\n",
    "                print(\"-------------------\")\n",
    "\n",
    "            print(\"\\n\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m input_path = \u001B[33m'\u001B[39m\u001B[33mcaptured_images\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      4\u001B[39m output_path = \u001B[33m'\u001B[39m\u001B[33mdetections\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m class_names = \u001B[43mmodel\u001B[49m.names\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m os.listdir(input_path):\n\u001B[32m      9\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m file.lower().endswith((\u001B[33m\"\u001B[39m\u001B[33m.png\u001B[39m\u001B[33m\"\u001B[39m)):\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência em tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mss\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 (no detections), 146.7ms\n",
      "Speed: 3.2ms preprocess, 146.7ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 4 tools, 147.5ms\n",
      "Speed: 2.8ms preprocess, 147.5ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Detetou 4 objetos.\n",
      "Moved to object 1 at (720, 594)\n",
      "Moved to object 2 at (564, 517)\n",
      "Moved to object 3 at (409, 440)\n",
      "Moved to object 4 at (1168, 803)\n",
      "\n",
      "0: 416x640 1 box, 4 coins, 2 tools, 122.9ms\n",
      "Speed: 2.1ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Detetou 7 objetos.\n",
      "Moved to object 1 at (928, 411)\n",
      "Moved to object 2 at (864, 443)\n",
      "Moved to object 3 at (802, 474)\n",
      "Moved to object 4 at (745, 910)\n",
      "Moved to object 5 at (961, 721)\n",
      "Moved to object 6 at (1114, 654)\n",
      "Moved to object 7 at (943, 975)\n",
      "\n",
      "0: 416x640 (no detections), 124.3ms\n",
      "Speed: 2.3ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 55\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;66;03m# Pausa breve, entre objetos\u001B[39;00m\n\u001B[1;32m     53\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.25\u001B[39m)  \u001B[38;5;66;03m# Adjust delay as needed\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Carregar o modelo\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# função que captura o ecrã e devolve a imagem\n",
    "def capture_screen():\n",
    "    with mss.mss() as sct:\n",
    "        screenshot = sct.grab(sct.monitors[1])  # Capturar do monitor principal\n",
    "        img = np.array(screenshot)  # Converter em imagem\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR) # Converter BGRA para RGB\n",
    "        img_height, img_width, _ = img.shape\n",
    "\n",
    "        # Opcionalmente, guardar a imagem capturada\n",
    "        # timestamp = time.strftime(\"%Y%m%d-%H%M%S-%f\")  # Include microseconds\n",
    "        # img_path = os.path.join('captured_images', f\"capture_{timestamp}.jpg\")\n",
    "        # cv2.imwrite(img_path, img)\n",
    "\n",
    "        return img, timestamp, img_width, img_height\n",
    "\n",
    "while True:\n",
    "    img, timestamp, img_width, img_height = capture_screen()\n",
    " \n",
    "    #results = model.predict(source=img, save=True, save_txt=True, conf=0.1) \n",
    "    results = model(img)\n",
    "\n",
    "    # Extract detections (bounding boxes)\n",
    "    detections = results[0].boxes.xyxy  # Bounding boxes (x1, y1, x2, y2)\n",
    "\n",
    "    if len(detections) > 0:\n",
    "        print(f\"Detetou {len(detections)} objetos.\")\n",
    "\n",
    "        # Opcionalmente, guardar imagem com as deteções\n",
    "        annotated_frame = results[0].plot()  # Draw bounding boxes on the image\n",
    "        result_path = os.path.join('detections', f\"result_{timestamp}.jpg\")\n",
    "        cv2.imwrite(result_path, annotated_frame)\n",
    "\n",
    "        for i, (x1, y1, x2, y2) in enumerate(detections.tolist()):\n",
    "            # Calculate the center of the object\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "\n",
    "            # converter coordenadas\n",
    "            scaled_x = int((center_x / img_width) * screen_width)\n",
    "            scaled_y = int((center_y / img_height) * screen_height)\n",
    "\n",
    "            # mover o rato\n",
    "            pyautogui.moveTo(scaled_x, scaled_y, duration=0.3)\n",
    "            pyautogui.click()\n",
    "            print(f\"Moved to object {i+1} at ({scaled_x}, {scaled_y})\")\n",
    "\n",
    "            # Pausa breve, entre objetos\n",
    "            time.sleep(0.25)  # Adjust delay as needed\n",
    "\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
